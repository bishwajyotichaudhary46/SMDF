{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from SMDF.logging import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Full Stack Data Science\\\\Time Series Analysis\\\\MAJOR PROJECT\\\\SMDF\\\\research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Full Stack Data Science\\Time Series Analysis\\MAJOR PROJECT\\SMDF\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForecastingPipeline:\n",
    "    def __init__(self):\n",
    "        self.M01AB = tf.saved_model.load(Path(\"artifacts/model_trainer/M01AB\"))\n",
    "        self.M01AE = tf.saved_model.load(\"artifacts/model_trainer/M01AE\")\n",
    "        self.N02BA = tf.saved_model.load(\"artifacts/model_trainer/N02BA\")\n",
    "        self.N02BE = tf.saved_model.load(\"artifacts/model_trainer/N02BE\")\n",
    "        self.N05B = tf.saved_model.load(\"artifacts/model_trainer/N05B\")\n",
    "        self.N05C = tf.saved_model.load(\"artifacts/model_trainer/N05C\")\n",
    "        self.R03 = tf.saved_model.load(\"artifacts/model_trainer/R03\")\n",
    "        self.R06 = tf.saved_model.load(\"artifacts/model_trainer/R06\")\n",
    "        self.train = pd.read_csv(\"artifacts/data_spliting/train.csv\")\n",
    "        self.test = pd.read_csv(\"artifacts/data_spliting/test.csv\")\n",
    "        self.scaler = joblib\n",
    "\n",
    "    def noramalizing_data(self,column_name):\n",
    "        scaler = StandardScaler()\n",
    "        #self.train.drop(columns=[\"datum\",\"Year\",\"Month\",\"Hour\",\"Weekday Name\"],inplace=True)\n",
    "        #self.test.drop(columns=[\"datum\",\"Year\",\"Month\",\"Hour\",\"Weekday Name\"],inplace=True)\n",
    "\n",
    "        train_data = scaler.fit_transform(self.train[column_name].values.reshape(-1,1))\n",
    "\n",
    "        test_data = scaler.transform(self.test[column_name].values.reshape(-1,1))\n",
    "\n",
    "        \n",
    "        logger.info(test_data.shape)\n",
    "        \n",
    "        #print(test_data)\n",
    "        return  test_data,train_data,scaler\n",
    "    \n",
    "    def test_spliting(self,column_name):\n",
    "        train, test,scaler = self.noramalizing_data(column_name)\n",
    "        window_size = 60\n",
    "        # Concatenate train data to test data\n",
    "        dataset_total = np.concatenate((train, test), axis = 0)\n",
    "        # Split test data and last window-size of train data\n",
    "        inputs = dataset_total[len(dataset_total) - len(test) - window_size:]\n",
    "        # Do the same thing for test data\n",
    "        X_test = []\n",
    "        y_test = []\n",
    "        for i in range(window_size, window_size+len(test)):\n",
    "            X_test.append(inputs[i-window_size:i,:]) \n",
    "            y_test.append(inputs[i,-1]) # consider Close as target\n",
    "        # Change them to numpy array\n",
    "        X_test, y_test = np.array(X_test).astype('float32'), np.array(y_test).reshape(-1, 1)\n",
    "        logger.info(X_test.shape)\n",
    "    \n",
    "        return X_test,y_test,scaler\n",
    "\n",
    "\n",
    "    def helper_forecast(self,column_name,key):\n",
    "        X_test, _,scaler = self.test_spliting(column_name)\n",
    "        \n",
    "        logger.info(\"Forecasting Start \")\n",
    "        logger.info(X_test.shape)\n",
    "        models = [self.M01AB,\n",
    "                  self.M01AE,\n",
    "                  self.N02BA,\n",
    "                  self.N02BE,\n",
    "                  self.N05B,\n",
    "                  self.N05C,\n",
    "                  self.R03,\n",
    "                  self.R06]\n",
    "        time_distribution = ['time_distributed_1',\n",
    "                             'time_distributed_3',\n",
    "                             'time_distributed_5',\n",
    "                             'time_distributed_7',\n",
    "                             'time_distributed_9',\n",
    "                             'time_distributed_11',\n",
    "                             'time_distributed_13',\n",
    "                             'time_distributed_15']\n",
    "        \n",
    "        x_input=X_test[-1:].reshape(1,-1)\n",
    "        \n",
    "        \n",
    "        temp_input=list(x_input)\n",
    "        temp_input=temp_input[0].tolist()\n",
    "        logger.info(len(temp_input))\n",
    "        \n",
    "    \n",
    "        lst_output = []\n",
    "        n_step = 60\n",
    "        i = 0\n",
    "        while i<30:\n",
    "        \n",
    "            if len(temp_input) >60:\n",
    "                x_input=np.array(temp_input[1:])\n",
    "                x_input=x_input.reshape(1,-1)\n",
    "                x_input = x_input.reshape((1, n_step, 1))\n",
    "                #print(x_input)\n",
    "                #forecast.append(x_input)\n",
    "                #print(forecast)\n",
    "                #logger.info(\"60 >\")\n",
    "                x_input = tf.constant(x_input, dtype=tf.float32)\n",
    "                model = models[key].signatures[\"serving_default\"]\n",
    "                test_predict = model(x_input)\n",
    "                #logger.info(test_predict)\n",
    "                #print(test_predict)\n",
    "                predictions = test_predict[time_distribution[key]].numpy()\n",
    "                temp_input=temp_input[1:]\n",
    "                lst_output.extend(predictions[0][0].tolist())\n",
    "                i=i+1\n",
    "\n",
    "            else:\n",
    "                x_input = np.array(x_input)\n",
    "                x_input = x_input.reshape((1, n_step,1))\n",
    "                \n",
    "                #x_input = x_input.astype(float) \n",
    "                model = models[key].signatures[\"serving_default\"]\n",
    "                test_predict = model(tf.constant(x_input))\n",
    "                #logger.info(test_predict)\n",
    "                #print(test_predict)\n",
    "                predictions = test_predict[time_distribution[key]].numpy()\n",
    "                #yhat = model.predict(x_input, verbose=0)\n",
    "                temp_input.extend(predictions[0][0].tolist())\n",
    "                lst_output.extend(predictions[0][0].tolist())\n",
    "                i = i+1\n",
    "                #logger.info(type(temp_input[0]))\n",
    "                    \n",
    "       \n",
    "\n",
    "        \n",
    "        return lst_output,scaler\n",
    "    def forecasting(self):\n",
    "        \n",
    "        today = datetime.datetime.now().strftime('%m/%d/%Y')\n",
    "        forecast_dates=pd.date_range(start=today, periods = 30)\n",
    "        forecast=pd.DataFrame(forecast_dates,columns=['Date'])\n",
    "        forecast['Date']=pd.to_datetime(forecast['Date'])\n",
    "        forecast.sort_values('Date',inplace=True)\n",
    "        columns = [\"M01AB\",\n",
    "            \"M01AE\",\n",
    "            \"N02BA\",\n",
    "            \"N02BE\",\n",
    "            \"N05B\",\n",
    "            \"N05C\",\n",
    "            \"R03\",\n",
    "            \"R06\"]\n",
    "        for i,val in enumerate(columns):\n",
    "            forecast_data,scaler = self.helper_forecast(val,i)\n",
    "            forecast_data=scaler.inverse_transform(np.array(forecast_data).reshape(-1, 1))\n",
    "            forecast[val] = forecast_data\n",
    "            \n",
    "        return forecast.to_csv(\"artifacts/forecast_data/forecast.csv\",index=False),forecast\n",
    "    \n",
    "                \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-03 08:24:13,481: INFO: 3442374582: (422, 1)]\n",
      "[2023-07-03 08:24:13,498: INFO: 3442374582: (1684, 60, 1)]\n",
      "[2023-07-03 08:24:13,511: INFO: 3442374582: Forecasting Start ]\n",
      "[2023-07-03 08:24:13,511: INFO: 3442374582: (1684, 60, 1)]\n",
      "[2023-07-03 08:24:13,511: INFO: 3442374582: 60]\n",
      "[2023-07-03 08:24:16,231: INFO: 3442374582: (422, 1)]\n",
      "[2023-07-03 08:24:16,246: INFO: 3442374582: (1684, 60, 1)]\n",
      "[2023-07-03 08:24:16,246: INFO: 3442374582: Forecasting Start ]\n",
      "[2023-07-03 08:24:16,246: INFO: 3442374582: (1684, 60, 1)]\n",
      "[2023-07-03 08:24:16,252: INFO: 3442374582: 60]\n",
      "[2023-07-03 08:24:16,631: INFO: 3442374582: (422, 1)]\n",
      "[2023-07-03 08:24:16,641: INFO: 3442374582: (1684, 60, 1)]\n",
      "[2023-07-03 08:24:16,641: INFO: 3442374582: Forecasting Start ]\n",
      "[2023-07-03 08:24:16,646: INFO: 3442374582: (1684, 60, 1)]\n",
      "[2023-07-03 08:24:16,646: INFO: 3442374582: 60]\n",
      "[2023-07-03 08:24:17,026: INFO: 3442374582: (422, 1)]\n",
      "[2023-07-03 08:24:17,031: INFO: 3442374582: (1684, 60, 1)]\n",
      "[2023-07-03 08:24:17,036: INFO: 3442374582: Forecasting Start ]\n",
      "[2023-07-03 08:24:17,040: INFO: 3442374582: (1684, 60, 1)]\n",
      "[2023-07-03 08:24:17,041: INFO: 3442374582: 60]\n",
      "[2023-07-03 08:24:17,407: INFO: 3442374582: (422, 1)]\n",
      "[2023-07-03 08:24:17,411: INFO: 3442374582: (1684, 60, 1)]\n",
      "[2023-07-03 08:24:17,411: INFO: 3442374582: Forecasting Start ]\n",
      "[2023-07-03 08:24:17,411: INFO: 3442374582: (1684, 60, 1)]\n",
      "[2023-07-03 08:24:17,416: INFO: 3442374582: 60]\n",
      "[2023-07-03 08:24:17,891: INFO: 3442374582: (422, 1)]\n",
      "[2023-07-03 08:24:17,896: INFO: 3442374582: (1684, 60, 1)]\n",
      "[2023-07-03 08:24:17,901: INFO: 3442374582: Forecasting Start ]\n",
      "[2023-07-03 08:24:17,901: INFO: 3442374582: (1684, 60, 1)]\n",
      "[2023-07-03 08:24:17,906: INFO: 3442374582: 60]\n",
      "[2023-07-03 08:24:18,271: INFO: 3442374582: (422, 1)]\n",
      "[2023-07-03 08:24:18,281: INFO: 3442374582: (1684, 60, 1)]\n",
      "[2023-07-03 08:24:18,281: INFO: 3442374582: Forecasting Start ]\n",
      "[2023-07-03 08:24:18,286: INFO: 3442374582: (1684, 60, 1)]\n",
      "[2023-07-03 08:24:18,291: INFO: 3442374582: 60]\n",
      "[2023-07-03 08:24:18,651: INFO: 3442374582: (422, 1)]\n",
      "[2023-07-03 08:24:18,656: INFO: 3442374582: (1684, 60, 1)]\n",
      "[2023-07-03 08:24:18,661: INFO: 3442374582: Forecasting Start ]\n",
      "[2023-07-03 08:24:18,661: INFO: 3442374582: (1684, 60, 1)]\n",
      "[2023-07-03 08:24:18,661: INFO: 3442374582: 60]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "          Date      M01AB     M01AE     N02BA      N02BE       N05B      N05C  \\\n",
       " 0  2023-07-03  10.862004  4.971833  6.038793  16.590708   6.143906 -0.060594   \n",
       " 1  2023-07-04   8.090595  4.390884  4.598959  16.222011  16.128204  0.142665   \n",
       " 2  2023-07-05   8.090595  4.390884  4.598959  16.222011  16.128204  0.142665   \n",
       " 3  2023-07-06   5.574401  3.633947  3.364209  19.972835   6.323010  0.462129   \n",
       " 4  2023-07-07   5.574401  3.633947  3.364209  19.972835   6.323010  0.462129   \n",
       " 5  2023-07-08   0.811251  1.929617  3.016167  20.056146   8.635968  0.433374   \n",
       " 6  2023-07-09   0.811251  1.929617  3.016167  20.056146   8.635968  0.433374   \n",
       " 7  2023-07-10   7.820029  3.316140  1.492194  25.510817   6.302610  0.824410   \n",
       " 8  2023-07-11   7.820029  3.316140  1.492194  25.510817   6.302610  0.824410   \n",
       " 9  2023-07-12   4.491529  3.640577  2.418786  23.047793   6.924994  0.127611   \n",
       " 10 2023-07-13   4.491529  3.640577  2.418786  23.047793   6.924994  0.127611   \n",
       " 11 2023-07-14   3.448121  6.463330  0.592066  24.541675   8.264549  0.356315   \n",
       " 12 2023-07-15   3.448121  6.463330  0.592066  24.541675   8.264549  0.356315   \n",
       " 13 2023-07-16   7.871901  3.856241  2.566859  21.877644   8.387670  0.513956   \n",
       " 14 2023-07-17   7.871901  3.856241  2.566859  21.877644   8.387670  0.513956   \n",
       " 15 2023-07-18   4.671924  2.624388  2.286435  26.152402  11.662394  1.617190   \n",
       " 16 2023-07-19   4.671924  2.624388  2.286435  26.152402  11.662394  1.617190   \n",
       " 17 2023-07-20   5.373305  5.082222  4.007535  20.851870   6.556919 -0.149576   \n",
       " 18 2023-07-21   5.373305  5.082222  4.007535  20.851870   6.556919 -0.149576   \n",
       " 19 2023-07-22   3.753757  3.520642  3.886890  16.874873  10.770563  0.203845   \n",
       " 20 2023-07-23   3.753757  3.520642  3.886890  16.874873  10.770563  0.203845   \n",
       " 21 2023-07-24   4.374593  4.130535  3.095048  25.254065   6.932529  0.278270   \n",
       " 22 2023-07-25   4.374593  4.130535  3.095048  25.254065   6.932529  0.278270   \n",
       " 23 2023-07-26   4.196873  4.270743  3.488908  23.506311   6.328483  1.104981   \n",
       " 24 2023-07-27   4.196873  4.270743  3.488908  23.506311   6.328483  1.104981   \n",
       " 25 2023-07-28   6.622773  2.361414  4.912588  22.103781   7.303722  0.406593   \n",
       " 26 2023-07-29   6.622773  2.361414  4.912588  22.103781   7.303722  0.406593   \n",
       " 27 2023-07-30   6.085258  6.395459  4.818481  22.523173  10.337858  1.046595   \n",
       " 28 2023-07-31   6.085258  6.395459  4.818481  22.523173  10.337858  1.046595   \n",
       " 29 2023-08-01   7.193709  5.102301  2.578183  27.406562  10.858318  0.305189   \n",
       " \n",
       "          R03       R06  \n",
       " 0   0.929774  2.001550  \n",
       " 1   1.211504  4.993045  \n",
       " 2   1.211504  4.993045  \n",
       " 3   2.597705  4.191115  \n",
       " 4   2.597705  4.191115  \n",
       " 5   3.453316  4.580619  \n",
       " 6   3.453316  4.580619  \n",
       " 7   1.418720  2.597036  \n",
       " 8   1.418720  2.597036  \n",
       " 9   3.041557  4.092098  \n",
       " 10  3.041557  4.092098  \n",
       " 11  2.235128  6.324208  \n",
       " 12  2.235128  6.324208  \n",
       " 13  1.855978  1.882647  \n",
       " 14  1.855978  1.882647  \n",
       " 15  1.235569  3.663594  \n",
       " 16  1.235569  3.663594  \n",
       " 17  3.528153  4.126664  \n",
       " 18  3.528153  4.126664  \n",
       " 19  1.607756  2.900378  \n",
       " 20  1.607756  2.900378  \n",
       " 21  1.509411  2.504044  \n",
       " 22  1.509411  2.504044  \n",
       " 23  2.489180  4.298888  \n",
       " 24  2.489180  4.298888  \n",
       " 25  1.126117  3.416550  \n",
       " 26  1.126117  3.416550  \n",
       " 27 -0.416222  2.488772  \n",
       " 28 -0.416222  2.488772  \n",
       " 29  2.234039  3.907072  )"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_cls = ForecastingPipeline()\n",
    "forecast_cls.forecasting()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
