{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Full Stack Data Science\\\\Time Series Analysis\\\\MAJOR PROJECT\\\\SMDF\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Full Stack Data Science\\Time Series Analysis\\MAJOR PROJECT\\SMDF\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Full Stack Data Science\\\\Time Series Analysis\\\\MAJOR PROJECT\\\\SMDF'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SMDF.constants import *\n",
    "from SMDF.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from SMDF.logging import logger\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    def get_data_transform(self):\n",
    "        data = pd.read_csv(self.config.data_path)\n",
    "        missing = data.isnull().sum()\n",
    "        logger.info(missing)\n",
    "        num_column =[\"M01AB\",\"M01AE\",\"N02BA\",\"N02BE\",\"N05B\",\"N05C\",\"R03\",\"R06\"]\n",
    "        data[num_column].fillna(\"median\",inplace=True)\n",
    "        logger.info(\"filling Missing value done sucessfully !\")\n",
    "        data.set_index(\"datum\",inplace=True)\n",
    "        dict_lower = {}\n",
    "        dict_upper = {}\n",
    "        targets = [\"M01AB\",\"M01AE\",\"N02BA\",\"N02BE\",\"N05B\",\"N05C\",\"R03\",\"R06\"]\n",
    "        for i,var in enumerate(targets):\n",
    "            irq = data[var].quantile(0.75) - data[var].quantile(0.25)\n",
    "            lower_bridge = data[var].quantile(0.25) -(irq*1.5)\n",
    "            upper_bridge = data[var].quantile(0.75) + (irq*1.5)\n",
    "            print(f\"Lower bound of {targets[i]}:{lower_bridge}\")\n",
    "            print(f\"Upper bound of {targets[i]}:{upper_bridge}\")\n",
    "            print(\"**\"*20)\n",
    "            dict_lower[targets[i]] = [lower_bridge]\n",
    "            dict_upper[targets[i]] = [upper_bridge]\n",
    "        \n",
    "        logger.info(f\"suceesfully find upper and Lower bound\")\n",
    "        outlier_clmn = [] \n",
    "        for i in targets:\n",
    "            x = [int(x) for x in dict_lower[i]]\n",
    "            y = [int(y) for y in dict_upper[i]]\n",
    "            \n",
    "            if (x[0] and y[0]) > data[i].min():\n",
    "                outlier_clmn.append(i)\n",
    "        for i in outlier_clmn:\n",
    "            x = [int(x) for x in dict_upper[i]]\n",
    "            data.loc[data[i] >= x[0],i] = int(x[0])\n",
    "\n",
    "        return data.to_csv(\"artifacts/data_transformation/salesDaily.csv\",index=True)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-28 10:17:28,806: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-06-28 10:17:28,811: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-06-28 10:17:28,816: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2023-06-28 10:17:28,820: INFO: common: created directory at: artifacts]\n",
      "[2023-06-28 10:17:28,821: INFO: common: created directory at: artifacts/data_transformation]\n",
      "[2023-06-28 10:17:28,837: INFO: 337311858: Unnamed: 0    0\n",
      "datum         0\n",
      "M01AB         0\n",
      "M01AE         0\n",
      "N02BA         0\n",
      "N02BE         0\n",
      "N05B          0\n",
      "N05C          0\n",
      "R03           0\n",
      "R06           0\n",
      "dtype: int64]\n",
      "[2023-06-28 10:17:28,846: INFO: 337311858: filling Missing value done sucessfully !]\n",
      "Lower bound of M01AB:-2.505\n",
      "Upper bound of M01AB:12.175\n",
      "****************************************\n",
      "Lower bound of M01AE:-1.8570000000000002\n",
      "Upper bound of M01AE:9.335\n",
      "****************************************\n",
      "Lower bound of N02BA:-2.8000000000000007\n",
      "Upper bound of N02BA:10.0\n",
      "****************************************\n",
      "Lower bound of N02BE:-9.949999999999996\n",
      "Upper bound of N02BE:67.25\n",
      "****************************************\n",
      "Lower bound of N05B:-5.5\n",
      "Upper bound of N05B:22.5\n",
      "****************************************\n",
      "Lower bound of N05C:-1.5\n",
      "Upper bound of N05C:2.5\n",
      "****************************************\n",
      "Lower bound of R03:-9.5\n",
      "Upper bound of R03:18.5\n",
      "****************************************\n",
      "Lower bound of R06:-3.5\n",
      "Upper bound of R06:8.5\n",
      "****************************************\n",
      "[2023-06-28 10:17:28,899: INFO: 337311858: suceesfully find upper and Lower bound]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_12692\\337311858.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[num_column].fillna(\"median\",inplace=True)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    data_transformation.get_data_transform()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
