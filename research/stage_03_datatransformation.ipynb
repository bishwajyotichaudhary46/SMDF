{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Full Stack Data Science\\\\Time Series Analysis\\\\MAJOR PROJECT\\\\SMDF\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Full Stack Data Science\\Time Series Analysis\\MAJOR PROJECT\\SMDF\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Full Stack Data Science\\\\Time Series Analysis\\\\MAJOR PROJECT\\\\SMDF'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    sales_data: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SMDF.constants import *\n",
    "from SMDF.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            sales_data=config.sales_data\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from SMDF.logging import logger\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    def get_data_transform(self):\n",
    "        data_1 = pd.read_csv(self.config.data_path)\n",
    "        sales = pd.read_csv(self.config.sales_data)\n",
    "        sales[[\"datum\",\"M01AB\",\"M01AE\",\"N02BA\",\"N02BE\",\"N05B\",\"N05C\",\"R03\",\"R06\"]] = sales[[\"datum\",\"mo1ab\",\"mo1ae\",\"no2ba\",\"no2be\",\"no5b\",\"no5c\",\"r06\",\"ro3\"]]\n",
    "        data=pd.concat([data_1,sales])\n",
    "        missing = data.isnull().sum()\n",
    "        logger.info(missing)\n",
    "        num_column =[\"M01AB\",\"M01AE\",\"N02BA\",\"N02BE\",\"N05B\",\"N05C\",\"R03\",\"R06\"]\n",
    "        data[num_column].fillna(\"median\",inplace=True)\n",
    "        logger.info(\"filling Missing value done sucessfully !\")\n",
    "        data.set_index(\"datum\",inplace=True)\n",
    "        dict_lower = {}\n",
    "        dict_upper = {}\n",
    "        targets = [\"M01AB\",\"M01AE\",\"N02BA\",\"N02BE\",\"N05B\",\"N05C\",\"R03\",\"R06\"]\n",
    "        for i,var in enumerate(targets):\n",
    "            irq = data[var].quantile(0.75) - data[var].quantile(0.25)\n",
    "            lower_bridge = data[var].quantile(0.25) -(irq*1.5)\n",
    "            upper_bridge = data[var].quantile(0.75) + (irq*1.5)\n",
    "            print(f\"Lower bound of {targets[i]}:{lower_bridge}\")\n",
    "            print(f\"Upper bound of {targets[i]}:{upper_bridge}\")\n",
    "            print(\"**\"*20)\n",
    "            dict_lower[targets[i]] = [lower_bridge]\n",
    "            dict_upper[targets[i]] = [upper_bridge]\n",
    "        \n",
    "        logger.info(f\"suceesfully find upper and Lower bound\")\n",
    "        outlier_clmn = [] \n",
    "        for i in targets:\n",
    "            x = [int(x) for x in dict_lower[i]]\n",
    "            y = [int(y) for y in dict_upper[i]]\n",
    "            \n",
    "            if (x[0] and y[0]) > data[i].min():\n",
    "                outlier_clmn.append(i)\n",
    "        for i in outlier_clmn:\n",
    "            x = [int(x) for x in dict_upper[i]]\n",
    "            data.loc[data[i] >= x[0],i] = int(x[0])\n",
    "\n",
    "        return data.to_csv(\"artifacts/data_transformation/salesDaily.csv\",index=True)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-05 11:02:44,053: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-07-05 11:02:44,068: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-07-05 11:02:44,079: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2023-07-05 11:02:44,082: INFO: common: created directory at: artifacts]\n",
      "[2023-07-05 11:02:44,085: INFO: common: created directory at: artifacts/data_transformation]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-05 11:02:44,298: INFO: 3265334080: datum              0\n",
      "M01AB              0\n",
      "M01AE              0\n",
      "N02BA              0\n",
      "N02BE              0\n",
      "N05B               0\n",
      "N05C               0\n",
      "R03                0\n",
      "R06                0\n",
      "Year               1\n",
      "Month              1\n",
      "Hour               1\n",
      "Weekday Name       1\n",
      "mfpid           2106\n",
      "mo1ab           2106\n",
      "mo1ae           2106\n",
      "no2ba           2106\n",
      "no2be           2106\n",
      "no5b            2106\n",
      "no5c            2106\n",
      "r06             2106\n",
      "ro3             2106\n",
      "user_id         2106\n",
      "dtype: int64]\n",
      "[2023-07-05 11:02:44,304: INFO: 3265334080: filling Missing value done sucessfully !]\n",
      "Lower bound of M01AB:-2.505\n",
      "Upper bound of M01AB:12.175\n",
      "****************************************\n",
      "Lower bound of M01AE:-1.8539999999999992\n",
      "Upper bound of M01AE:9.329999999999998\n",
      "****************************************\n",
      "Lower bound of N02BA:-2.8000000000000007\n",
      "Upper bound of N02BA:10.0\n",
      "****************************************\n",
      "Lower bound of N02BE:-9.949999999999996\n",
      "Upper bound of N02BE:67.25\n",
      "****************************************\n",
      "Lower bound of N05B:-5.5\n",
      "Upper bound of N05B:22.5\n",
      "****************************************\n",
      "Lower bound of N05C:-1.5\n",
      "Upper bound of N05C:2.5\n",
      "****************************************\n",
      "Lower bound of R03:-9.5\n",
      "Upper bound of R03:18.5\n",
      "****************************************\n",
      "Lower bound of R06:-3.5\n",
      "Upper bound of R06:8.5\n",
      "****************************************\n",
      "[2023-07-05 11:02:44,392: INFO: 3265334080: suceesfully find upper and Lower bound]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_12376\\3265334080.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[num_column].fillna(\"median\",inplace=True)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    data_transformation.get_data_transform()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
